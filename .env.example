# Medical AI Assistant Configuration

# Models Directory
# Where AI models will be stored (requires ~15GB)
MODELS_DIR=/path/to/models

# MCP Servers Configuration
# Enable/disable specific servers
MCP_MEDGEMMA_ENABLED=true
MCP_HEAR_ENABLED=false
MCP_TXGEMMA_ENABLED=false
MCP_FOUNDATIONS_ENABLED=false

# Model Variants
# Choose model sizes (4b for faster, 27b for better quality)
MEDGEMMA_MODEL=google/medgemma-4b-it
TXGEMMA_MODEL=google/txgemma-2b-predict

# GPU Configuration
# Set to 'cpu' if no GPU available
DEVICE=cuda
# GPU device ID (0, 1, 2, etc.)
CUDA_DEVICE=0

# Performance Settings
# Max tokens to generate
MAX_NEW_TOKENS=512
# Temperature for generation (0.0-1.0)
TEMPERATURE=0.7
# Batch size for processing
BATCH_SIZE=1

# Logging
LOG_LEVEL=INFO
# Log file path (optional)
LOG_FILE=

# Development
# Set to 'true' for development mode
DEV_MODE=false
